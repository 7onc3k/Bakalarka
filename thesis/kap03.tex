\chapter{Metodika}
\label{kap:metodika}

\section{Výběr projektu pro case study}

\begin{draft}
Experiment potřebuje projekt, na kterém lze spustit více běhů s~různým nastavením instrukcí a~objektivně měřit výsledky. Zvolený projekt musí splňovat:

\begin{itemize}
    \item \textbf{Hard logic} --- jasná business pravidla, ne subjektivní výstupy
    \item \textbf{Jasné invarianty} --- deterministické chování, ověřitelná správnost
    \item \textbf{Testovatelné} --- kvalitu výstupu lze měřit objektivně (testy, mutation score)
    \item \textbf{Přiměřená velikost} --- menší projekt umožňuje více experimentálních běhů
    \item \textbf{Reálný use case} --- prakticky využitelné, ne umělý příklad
\end{itemize}
\end{draft}

\subsection*{Systém upomínek faktur}

\begin{draft}
Systém pro automatické odesílání připomínek k~nezaplaceným fakturám. Obsahuje stavový automat pro sledování stavu faktury (nová, po splatnosti, upomínaná, eskalovaná), časové výpočty (pracovní dny, ochranné lhůty), pravidla pro eskalaci a~plánování odesílání upomínek.
\end{draft}

%% ==========================================================================
%% 3.2 Výzkumný přístup — NEW SECTION
%% ==========================================================================

\section{Výzkumný přístup: návrhový výzkum (DSR)}
\label{sec:vyzkumny-pristup}

\begin{draft}
Hevner et al. \cite{hevner2004} rozlišují v~informatickém výzkumu dva přístupy. Behaviorální výzkum popisuje a~vysvětluje existující jevy --- například jak vývojáři pracují s~AI nástroji. Návrhový výzkum (Design Science Research, DSR) naopak navrhuje nové artefakty a~ověřuje, jestli řeší daný problém. Rozdíl je v~tom, co je výstupem: popis světa, nebo nástroj který ho mění.

Tato práce spadá do návrhového výzkumu. Artefaktem je sada instrukcí pro AI coding agenta. Instrukce se navrhnou, agent s~nimi projede vývojový úkol, z~výstupu (kód, testy, git log) se vyhodnotí co fungovalo a~co ne, a~instrukce se podle toho upraví. Hevner tento postup formalizuje jako build-evaluate cyklus --- iterativní smyčku návrhu a~vyhodnocení, která se opakuje dokud artefakt nedosáhne požadované kvality.

\subsubsection*{Dvě fáze výzkumu}

Výzkum má dvě fáze, které odpovídají DSR cyklu:

\begin{enumerate}
    \item \textbf{Pilotní iterace} --- opakovaně navrhujeme a~vyhodnocujeme instrukce. Každá iterace je jeden build-evaluate cyklus: spustíme agenta, analyzujeme výstup, diagnostikujeme problém, upravíme instrukce. Zaznamenáváme co se měnilo a~proč. Konkrétní cílové chování a~metriky compliance popisuje sekce~\ref{sec:experimentalni-design}.
    \item \textbf{Komparativní variace} --- z~fungujících instrukcí systematicky měníme jednotlivé komponenty a~měříme dopad na chování agenta. Změna může být odebrání (ablace --- funguje agent bez této instrukce?) nebo nahrazení alternativou (substituce --- funguje jiná formulace stejného záměru?). Ablace ukáže \textit{jestli} komponenta záleží, substituce ukáže \textit{proč} a~\textit{v~jaké formě}.
\end{enumerate}

\subsubsection*{Case study a~generalizace}

Výzkum probíhá formou case study na jednom projektu (systém upomínek faktur). Yin \cite{yin2018} rozlišuje dva typy generalizace: statistickou (ze vzorku na populaci) a~analytickou (z~případu na teorii). Case study neumožňuje říct ``tento scaffolding funguje vždy'' --- k~tomu by byl potřeba velký vzorek projektů. Umožňuje ale identifikovat principy a~mechanismy: \textit{proč} určité instrukce fungují a~jiné ne, a~za jakých podmínek.

Více experimentálních běhů na jednom projektu odpovídá tomu, co Yin nazývá embedded single-case design --- jeden případ (projekt) s~více vnořenými jednotkami analýzy (jednotlivé běhy). DSR poskytuje celkový rámec (jak iterovat artefakt), case study poskytuje kontext (reálný projekt s~deterministickou logikou a~ověřitelnými výstupy).
\end{draft}

%% ==========================================================================
%% 3.3 Experimentální design
%% ==========================================================================

\section{Experimentální design}
\label{sec:experimentalni-design}

\subsection{Fixní proměnné}

\begin{raw}
[RAW] Všechny běhy sdílejí stejný setup --- jedinou proměnnou je obsah
\texttt{AGENTS.md}.

\begin{itemize}
    \item Prázdné GitHub repo (\texttt{AGENTS.md},
          \texttt{.opencode/config.json}, \texttt{.opencode/agents/build.md},
          auto-continue plugin)
    \item Specifikace v~GitHub Issue \#1 --- 24 acceptance criteria,
          doménový glossary, API contract, out of scope
    \item Auto-continue plugin (\texttt{session.idle} hook s~počítadlem
          restartů a~build/test kontrolou)
    \item Model: minimax-m2.5-free přes OpenCode
    \item System prompt \texttt{build.md} (\texttt{mode: primary},
          nahrazuje defaultní \texttt{qwen.txt}
          --- kódové konvence, žádné procesní instrukce)
\end{itemize}
\end{raw}

\subsection{Referenční implementace}

\begin{raw}
[RAW] Referenční implementace slouží dvěma účelům: validaci specifikace
a~vytvoření \textbf{behavioral test suite} pro měření funkční korektnosti
(viz sekce~\ref{sec:funkcni-korektnost}).

\textbf{Metoda: TDD z acceptance criteria.}
Postup odpovídá spec-first TDD \cite{mathews2024}: nejprve se napíší
behavioral testy přímo z~AC ve formátu Given/When/Then --- testy jsou
zpočátku červené (implementace neexistuje). Následně se implementuje
dunning system tak, aby testy postupně zelenaly. Tato sekvence zajišťuje,
že expected values pochází ze specifikace, nikoliv z~pozorování kódu
(test oracle problem \cite{mathews2024}).

\textbf{Behavioral testy, ne unit testy.}
Referenční testy testují chování systému přes veřejné API (vstupy a~výstupy
definované specifikací), nikoliv interní implementaci. Tento přístup
odpovídá black-box testování funkčních požadavků \cite{swebok2024}
a~metodice SWE-bench \cite{swebench2024}. Výhodou je přenositelnost:
stejné testy lze spustit na implementaci libovolného agentního běhu
bez znalosti jeho interní struktury.

\textbf{Validace specifikace.}
Implementace referenčního řešení odhaluje nejednoznačnosti a~mezery
v~acceptance criteria dříve než experimentální běhy.

\textbf{Výstup:} 40 behavioral testů (TypeScript/Vitest), spustitelné
na libovolné implementaci se standardizovaným API.
\end{raw}

\subsection{Pilotní iterace}

\begin{raw}
[RAW] DSR build-evaluate cyklus aplikovaný na instrukce.

Každá iterace:
\begin{enumerate}
    \item Spustit agenta s~aktuální verzí \texttt{AGENTS.md}
    \item Analyzovat výstup (git log, session trace, kód, testy)
    \item Diagnostikovat selhání --- kde a~proč agent nedodržel cílové chování
    \item Upravit instrukce s~odkazem na literaturu
    \item Opakovat dokud agent konzistentně demonstruje cílová chování
          (sekce~\ref{sec:co-a-jak-merime})
\end{enumerate}

\textbf{Výstup každé iterace:}
\begin{itemize}
    \item Aktualizovaný \texttt{AGENTS.md}
    \item CHANGELOG záznam: co se změnilo, proč, jaká evidence vedla ke~změně
    \item Behavioral trace z~git logu a~session trace
\end{itemize}

\textbf{Exit kritérium:}
Agent konzistentně demonstruje cílová chování definovaná
v~sekci~\ref{sec:co-a-jak-merime}. ``Konzistentně'' = v~posledním
běhu bez manuálního zásahu.
\end{raw}

\subsection{Komparativní variace}

\begin{raw}
[RAW] Z~fungující sady instrukcí (výstup pilotní fáze) systematicky
měníme jednotlivé komponenty a~měříme dopad na chování agenta.

\textbf{Dva typy změn:}
\begin{enumerate}
    \item \textbf{Ablace} --- odebrání komponenty úplně.
          Měří \textit{nutnost}: funguje agent bez této instrukce?
          Příklad: odebrat TDD instrukci $\rightarrow$ dělá agent TDD přirozeně?
    \item \textbf{Substituce} --- nahrazení komponenty alternativou.
          Měří \textit{efekt obsahu}: která varianta produkuje lepší výsledky?
          Příklad: ``strict TDD'' vs. ``impl-first, testy po stabilizaci''.
\end{enumerate}

Ablace ukáže \textit{jestli} komponenta záleží, substituce ukáže
\textit{proč} a~\textit{v~jaké formě}. Konkrétní dimenze variace
budou určeny na základě výsledků pilotní fáze --- identifikujeme
komponenty kde má smysl testovat alternativy.

Prompt sensitivity \cite{razavi2025} je přiznaná limitation: výsledky
mohou záviset na konkrétní formulaci, ne jen na přítomnosti/absenci
komponenty.
\end{raw}

%% ==========================================================================
%% 3.4 Co a jak měříme
%% ==========================================================================

\section{Co a jak měříme}
\label{sec:co-a-jak-merime}

\begin{raw}
[RAW] Tato sekce definuje co experiment měří a~jak. Každá podsekce
popisuje jednu oblast hodnocení: jaké chování od agenta očekáváme,
jaké metriky k~tomu sbíráme, a~jak je měříme.

Měření kombinuje tři přístupy: automatické skripty (git log, testy,
statická analýza), LLM-as-judge s~fixním rubrikem \cite{llmjudge2024}
(kvalita kódu a~procesních artefaktů), a~manuální review transkriptu
(behaviorální kódování).

Primární zdroje dat:
\begin{itemize}
    \item \textbf{Git log + GitHub API} --- commity, branches, PRs, issues
    \item \textbf{Session transcript} (\texttt{opencode export}) --- kompletní
          sekvence tool calls a~rozhodnutí agenta
    \item \textbf{Zdrojový kód agenta} --- vstup pro testy a~statickou analýzu
\end{itemize}
\end{raw}

\subsection{Porozumění a plánování}

\begin{raw}
[RAW]

\textbf{Cílové chování:}
\begin{description}
    \item[B1 --- přečte specifikaci před kódem.] Agent musí začít čtením
        Issue~\#1, ne kódem. Bez toho implementuje z~vlastních ``znalostí''
        (model weights), ne z~požadavků.
    \item[B2 --- decomponuje do sub-issues.] Menší úkoly mají vyšší
        úspěšnost \cite{ehsani2026failedprs}. Dekompozice ukazuje,
        že agent plánuje, ne jen kóduje.
    \item[B3 --- vytvoří architecture issue před kódem.] Plánování struktury
        (moduly, typy, API) před implementací. Agent vytvoří GitHub issue
        s~architektonickým návrhem, podle kterého pak skládá implementaci.
\end{description}

\textbf{Jak ověřit:}
\begin{itemize}
    \item B1: Transcript --- první tool call je čtení Issue~\#1 (manuální)
    \item B2: \texttt{gh issue list} --- vznikly sub-issues? (automatické)
    \item B3: GitHub --- existuje issue s~architekturou před prvním
          \texttt{.ts} souborem? (automatické)
\end{itemize}
\end{raw}

\subsection{Vývojový proces}

\begin{raw}
[RAW]

\textbf{Cílové chování:}
\begin{description}
    \item[B4 --- TDD test-first ze specifikace.] Expected values musí
        vycházet z~acceptance criteria, ne z~pozorování kódu. Obrana proti
        test oracle problému --- 68,1\,\% LLM-generovaných testů validuje
        chybné chování \cite{mathews2024}.
    \item[B5 --- branch per issue + PR workflow.] Bez branch-per-issue agent
        kombinuje nesouvisející práci \cite{gotel1994}. Kompletní cyklus
        branch $\to$ PR $\to$ merge $\to$ close zajišťuje traceability.
    \item[B6 --- průběžné commity.] Blob commit (vše najednou) znemožňuje
        retrospektivní analýzu. Průběžné commity umožňují ověřit pořadí
        test/implementace z~git logu.
\end{description}

\textbf{Jak ověřit:}
\begin{itemize}
    \item B4: Git log --- test soubor před src souborem per branch
          (automatické z~prefixů, manuální ověření z~transkriptu)
    \item B5: \texttt{git branch -a} vs issue count, \texttt{gh pr list}
          (automatické)
    \item B6: Commit count $>$ 1 per branch (automatické)
\end{itemize}

\textbf{Doplňkové metriky:}
\begin{itemize}
    \item TDD compliance (kvantitativní) --- podíl test-first cyklů
          ku celkovým implementačním cyklům (git log)
    \item Commit granularity --- počet commitů, průměrný počet řádků
          na commit \cite{ehsani2026failedprs}
\end{itemize}
\end{raw}

\subsection{Kvalita kódu}

\begin{raw}
[RAW]

\textbf{Cílové chování:}
\begin{description}
    \item[B7 --- lint + typecheck čistý.] Agent musí aktivně spustit linter
        a~type checker a~opravit nalezené problémy. Bez toho produkuje kód
        který může fungovat ale nerespektuje konvence.
\end{description}

\textbf{Automatické metriky:}
\begin{itemize}
    \item Lint warnings --- \texttt{eslint --format json}, počet
          varování a~chyb
    \item Typecheck errors --- \texttt{tsc --noEmit}, počet chyb
    \item Strict mode compliance --- počet \texttt{any} v~kódu
          (TypeScript strict mode penalizuje \texttt{any})
    \item Složitost kódu --- cyklomatická složitost per funkce
          (ESLint \texttt{complexity} rule), maximální délka funkce.
          SWE-bench používá McCabe jako jednu z~metrik \cite{swebench2024}.
\end{itemize}

\textbf{LLM-as-judge (Q7):}

Automatické metriky zachytí formální problémy, ale ne kvalitu designu.
LLM-as-judge \cite{llmjudge2024} hodnotí aspekty které nelze měřit
deterministicky:

\begin{itemize}
    \item Naming conventions (1--5) --- srozumitelné názvy proměnných a~funkcí
    \item Separation of concerns (1--5) --- logické rozdělení do modulů
    \item Idiomatický TypeScript (1--5) --- využití typového systému,
          pattern matching, funkcionální patterny
    \item Zbytečná komplexita (1--5, inverzně) --- over-engineering,
          nepotřebné abstrakce
\end{itemize}

Rubric je fixní pro všechny běhy. Validace: porovnání s~manuálním
hodnocením autora na vzorku.

[RAW] TODO: definovat přesný rubric pro Q7 (prompt + příklady per škála)
\end{raw}

\subsection{Kvalita testů}

\begin{raw}
[RAW]

\textbf{Metriky:}
\begin{description}
    \item[Mutation score (Stryker).] Podíl zabitých mutantů --- měří
        jestli agentovy testy skutečně detekují chyby, nebo jsou
        tautologické. Silnější prediktor než strukturální coverage ---
        36\,\% chyb odhalitelných pouze mutation testingem
        \cite{papadakis2019}. Harman et al. \cite{meta2025} potvrdili
        v~produkčním nasazení na Meta, že 70\,\% mutantů zůstává
        neodhalených i~při plném coverage.
    \item[AC coverage.] Kolik z~24 acceptance criteria má odpovídající
        test. Měří úplnost pokrytí požadavků, ne jen korektnost
        implementace. Mapování test $\to$ AC manuální nebo LLM-as-judge.
\end{description}

\textbf{Referenční hodnoty} (z~referenční implementace):
\begin{itemize}
    \item Mutation score: $\geq$ 60,7\,\%
    \item AC coverage: 24/24
\end{itemize}
\end{raw}

\subsection{Funkční korektnost}
\label{sec:funkcni-korektnost}

\begin{raw}
[RAW]

\textbf{Metrika: referenční test pass rate.}

40 behavioral testů odvozených z~acceptance criteria metodou TDD
ze specifikace \cite{mathews2024} (viz sekce referenční implementace).
Testují chování přes veřejné API --- nezávislé na interní struktuře
agentovy implementace. Odpovídá přístupu SWE-bench \cite{swebench2024}.

Pass rate = počet projitých testů / 40. Binární varianta (pass all / fail)
odpovídá metrice \% Resolved v~SWE-bench.

Doplňkově: API contract match --- \texttt{tsc} import + type-check
referenčních typů proti agentovu kódu. Ověřuje že agentova implementace
je kompatibilní s~definovaným rozhraním.
\end{raw}

\subsection{Kvalita procesních artefaktů}

\begin{raw}
[RAW]

\textbf{LLM-as-judge (Q8):}

Agent produkuje procesní artefakty (commit messages, issue descriptions,
PR descriptions) které nelze hodnotit automaticky. LLM-as-judge
\cite{llmjudge2024} hodnotí:

\begin{itemize}
    \item Commit messages --- popisnost, atomicita, konvenční prefix (1--5)
    \item Issue descriptions --- jasný scope, acceptance criteria, kontext (1--5)
    \item PR descriptions --- co a~proč, odkaz na issue (1--5)
\end{itemize}

Rubric fixní, stejný model a~prompt pro všechny běhy.

[RAW] TODO: definovat přesný rubric pro Q8 (prompt + příklady per škála)
\end{raw}

\subsection{Efektivita}

\begin{raw}
[RAW]

\begin{itemize}
    \item \textbf{E1 --- tokeny} (input/output): \texttt{opencode export}
          $\to$ JSON parsing. Měří náklady na API.
    \item \textbf{E2 --- trvání} (minuty): session timestamps.
    \item \textbf{E3 --- kompletní dokončení}: crash / no crash + důvod.
          Počet restartů auto-continue pluginu jako proxy pro autonomii.
\end{itemize}

S~N=1 per run jsou tyto metriky deskriptivní (porovnání napříč běhy),
ne inferenční (žádné p-hodnoty).
\end{raw}

\subsection{Entropy signály}

\begin{raw}
[RAW] Behaviorální patterny indikující nejistotu agenta. Nejsou formální
metrika s~číslem, ale kvalitativní behaviorální kódování z~git logu
a~session transkriptu.

\textbf{Signály:}
\begin{itemize}
    \item Opakované čtení stejného souboru bez změny
    \item Testy spouštěné bez předchozí změny kódu
    \item Cyklická explorace (agent se vrací k~souborům které už četl)
    \item Commit bursts (mnoho commitů v~krátkém čase)
    \item REPL debugging (opakované spouštění příkazů v~bashi)
\end{itemize}

\textbf{Účel:} Retrospektivní identifikace momentů kde agent ``tápe''
umožňuje kauzální analýzu --- co způsobilo problém a~jak instrukce
mohly zabránit odchylce. Kvantifikace (počet REPL sessions, unique/total
file reads ratio) je možná ale s~N=1 per run jen deskriptivní.
\end{raw}
